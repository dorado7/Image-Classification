{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorado7/Image-Classification/blob/main/MachineLearningwithDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koFaMT2UvVyN"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "import glob\n",
        "\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ht86UbhwAHw",
        "outputId": "4bf5012b-9641-4985-addc-3d8d784383b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/BrainMRI_CW'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swgCRxuUhSPC",
        "outputId": "71d9a95e-4389-41ca-d83f-cae04a0649e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGQGB_BUZ-Oo"
      },
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "transforms = T.Compose([ # Call Compose using the alias\n",
        "    T.Resize((150,150)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5,0.5,0.5],\n",
        "                        [0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "test_path = '/content/drive/MyDrive/BrainMRI_CW/Testing'\n",
        "train_path = '/content/drive/MyDrive/BrainMRI_CW/Training'\n",
        "train_loader = DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path, transform=transforms),\n",
        "    batch_size=256, shuffle=True # The batch size is according to the CPU memory ensure the allocated sizee is appropriate\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    torchvision.datasets.ImageFolder(test_path, transform=transforms),\n",
        "    batch_size=256, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fPdqGtIBUJil",
        "outputId": "d30472d9-8bc3-4dc7-e03e-539504afe797"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' needs to be completed '"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check initial image size\n",
        "\"\"\" needs to be completed \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHKNwvdHd0a3",
        "outputId": "2ba1dda7-0301-458b-ce7c-580e6dc05f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['glioma', 'meningioma', 'notumor', 'pituitary']\n"
          ]
        }
      ],
      "source": [
        "#Categories\n",
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27ifHOMAd7jA"
      },
      "outputs": [],
      "source": [
        "#CNN Network\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=6):\n",
        "        super(ConvNet,self).__init__()\n",
        "#CNN Network\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=6):\n",
        "        super(ConvNet,self).__init__()\n",
        "\n",
        "        #Output size after convolution filter\n",
        "       # ((w-f+2P)/s) +1\n",
        "\n",
        "        #Input shape= (256,3,150,150)\n",
        "\n",
        "        self.conv1=nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        self.relu1=nn.ReLU()\n",
        "\n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv2=nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2=nn.ReLU()\n",
        "\n",
        "        self.conv3=nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        self.relu3=nn.ReLU()\n",
        "\n",
        "        self.fc=nn.Linear(in_features=32*75*75, out_features=num_classes)\n",
        "\n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "\n",
        "        output=self.pool(output)\n",
        "\n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "\n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "\n",
        "        output=output.view(-1,32*75*75)\n",
        "\n",
        "        output=self.fc(output)\n",
        "        return output\n",
        "\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        self.relu1=nn.ReLU()\n",
        "\n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv2=nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2=nn.ReLU()\n",
        "\n",
        "        self.conv3=nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        self.relu3=nn.ReLU()\n",
        "\n",
        "        self.fc=nn.Linear(in_features=32*75*75, out_features=num_classes)\n",
        "\n",
        "        def forward(self,input):\n",
        "            output=self.conv1(input)\n",
        "            output=self.bn1(output)\n",
        "            output=self.relu1(output)\n",
        "\n",
        "            output=self.pool(output)\n",
        "\n",
        "            output=self.conv2(output)\n",
        "            output=self.relu2(output)\n",
        "\n",
        "            output=self.conv3(output)\n",
        "            output=self.bn3(output)\n",
        "            output=self.relu3(output)\n",
        "\n",
        "            output=output.view(-1,32*75*75)\n",
        "\n",
        "            output=self.fc(output)\n",
        "\n",
        "            return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOyM60qvyeu6"
      },
      "outputs": [],
      "source": [
        "model = ConvNet(num_classes=6).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-D6Jy8XybrQ"
      },
      "outputs": [],
      "source": [
        "# Optimiser and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpe8KfoRp2LF"
      },
      "outputs": [],
      "source": [
        "num_epochs=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPScq4wMyboo"
      },
      "outputs": [],
      "source": [
        "#calculating the size of training and testing set (check this)\n",
        "train_count = len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count = len(glob.glob(test_path+'/**/*.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvLXbEadybmD",
        "outputId": "9a022f0f-12ff-4831-dd12-2953bfd5ceda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5722 1311\n"
          ]
        }
      ],
      "source": [
        "print(train_count, test_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RIyg_LDlybht",
        "outputId": "e779c573-ad50-4b6a-db8f-5ec18e7eaa51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss: tensor(10.0723) Train Accuracy: 0.6022369800768962 Test Accuracy: 0.4988558352402746\n",
            "Epoch: 1 Train Loss: tensor(1.6306) Train Accuracy: 0.8210415938483048 Test Accuracy: 0.6216628527841342\n",
            "Epoch: 2 Train Loss: tensor(0.6111) Train Accuracy: 0.8841314225795176 Test Accuracy: 0.8535469107551488\n",
            "Epoch: 3 Train Loss: tensor(0.2410) Train Accuracy: 0.9388325760223698 Test Accuracy: 0.8863463005339436\n",
            "Epoch: 4 Train Loss: tensor(0.1959) Train Accuracy: 0.9369101712687872 Test Accuracy: 0.8779557589626239\n",
            "Epoch: 5 Train Loss: tensor(0.1483) Train Accuracy: 0.9627752534078994 Test Accuracy: 0.9206712433257056\n",
            "Epoch: 6 Train Loss: tensor(0.0979) Train Accuracy: 0.9772806710940231 Test Accuracy: 0.9466056445461479\n",
            "Epoch: 7 Train Loss: tensor(0.0547) Train Accuracy: 0.9800768961901433 Test Accuracy: 0.9481311975591151\n",
            "Epoch: 8 Train Loss: tensor(0.0443) Train Accuracy: 0.988465571478504 Test Accuracy: 0.9427917620137299\n",
            "Epoch: 9 Train Loss: tensor(0.0271) Train Accuracy: 0.9926599091226844 Test Accuracy: 0.9366895499618612\n"
          ]
        }
      ],
      "source": [
        "#Model training and saving best model\n",
        "\n",
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(10):\n",
        "\n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "\n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #This will calculate the loss\n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "\n",
        "\n",
        "        #Expalin\n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "\n",
        "        #This will calculate the accuracy\n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "\n",
        "    #Evaluation and training on testing dataset\n",
        "    model.eval()\n",
        "\n",
        "    test_accuracy=0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "\n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "\n",
        "    test_accuracy=test_accuracy/test_count\n",
        "\n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "\n",
        "    #Save the best model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(), 'best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgwGy2syybZv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1paHg01NW6qqMfJ3goYJc_1Sw7R6pmmA8",
      "authorship_tag": "ABX9TyPo4jsgIeAF4S6BppLNLDs2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}